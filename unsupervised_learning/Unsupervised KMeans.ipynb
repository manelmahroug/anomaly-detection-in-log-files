{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = ''\n",
    "#APP_SYS_NAME = 'BGL'\n",
    "APP_SYS_NAME = 'Thunderbird'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6388305",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = PROJECT_DIR + 'output/'\n",
    "RAW_DIR = PROJECT_DIR + 'raw_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa93594",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, confusion_matrix , precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from scipy.spatial.distance import cosine\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "random.seed(2)\n",
    "sys.path.append(PROJECT_DIR) # this is done to make the import of ad_feature_extraction work\n",
    "from ad_feature_extraction import parsers\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b2484a",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52e0153",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(BASE_DIR + APP_SYS_NAME + '_clusters2.csv')\n",
    "\n",
    "print(\"Input_data Shape:\",input_data.shape)\n",
    "print(input_data['label'].value_counts())\n",
    "\n",
    "sns.countplot(x=input_data['label'])\n",
    "plt.show()\n",
    "\n",
    "print(input_data[['clusters', 'label', 'text']].groupby(['clusters', 'label']).count())\n",
    "print(f\"Homogeneity Score: \\n {homogeneity_score(input_data['label'], input_data['clusters'])}\\n\")\n",
    "print(input_data[['cluster2', 'label', 'text']].groupby(['cluster2', 'label']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49412064",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "input_data['label'] = le.fit_transform(input_data['label']) # false:0 and true:1\n",
    "\n",
    "X = input_data[['tfidf_text']].dropna()\n",
    "y = input_data.loc[X.index,'label'].values\n",
    "\n",
    "print(\"columns for the X file\"+ str(X.columns))\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebea2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do tfidf and kmeans on input_data and get homegeneity and completeness scores.\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(X['tfidf_text'])\n",
    "print('tfidf shape', X_tfidf.shape)\n",
    "\n",
    "k = input_data['cluster2'].max() + 1\n",
    "print('Using k = ', k)\n",
    "kmeans = MiniBatchKMeans(n_clusters=k, n_init=10, batch_size=10000, random_state=0)\n",
    "# KMeans(k, random_state=0)\n",
    "kmeans.fit(X_tfidf)\n",
    "\n",
    "pred = kmeans.predict(X_tfidf)\n",
    "labels = y\n",
    "\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Completeness Score: \\n {completeness_score(labels, pred)}\\n\")\n",
    "print(f\"Homogeneity Score: \\n {homogeneity_score(labels, pred)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c88711",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# count log lines within each cluster\n",
    "output = X.copy()\n",
    "output['cluster2'] = pred\n",
    "output['label'] = input_data.loc[X.index, 'label']\n",
    "print(output.groupby(['cluster2', 'label']).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db709c6b",
   "metadata": {},
   "source": [
    "# Use label to determine which clusters are anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486241d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(output.groupby(['cluster2', 'label']).count())\n",
    "counts_by_label_df = output.groupby(['cluster2', 'label']).count().reset_index()\n",
    "pos_df = counts_by_label_df[counts_by_label_df['label'] == 1]\n",
    "neg_df = counts_by_label_df[counts_by_label_df['label'] == 0]\n",
    "anomaly_clusters = []\n",
    "normal_clusters = []\n",
    "for _, row in pos_df.iterrows():\n",
    "    cluster = row['cluster2']\n",
    "    pos = row['tfidf_text']\n",
    "    neg = neg_df[neg_df[\"cluster2\"] == cluster]['tfidf_text'].sum()\n",
    "    print(cluster, 'pos neg', pos, neg)\n",
    "    if pos > neg:\n",
    "        anomaly_clusters.append(cluster)\n",
    "\n",
    "for _, row in neg_df.iterrows():\n",
    "    cluster = row['cluster2']\n",
    "    neg = row['tfidf_text']\n",
    "    pos = pos_df[pos_df[\"cluster2\"] == cluster]['tfidf_text'].sum()\n",
    "    if neg >= pos:\n",
    "        normal_clusters.append(cluster)\n",
    "\n",
    "print('anomaly clusters', anomaly_clusters)\n",
    "print('normal clusters', normal_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5073f3",
   "metadata": {},
   "source": [
    "# Create summary report for clusters. Give example log line for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a142c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_file_name = BASE_DIR + APP_SYS_NAME + '_cluster_summary.csv'\n",
    "output_file = open(summary_file_name, 'w')\n",
    "with output_file:\n",
    "    writer = csv.writer(output_file)\n",
    "    writer.writerow(['is_anomaly', 'anomaly_count', 'normal_count',\n",
    "                     'cluster', 'pct_of_total',\n",
    "                     'most_similar_sample', 'most_similar_distance',\n",
    "                     'least_similar_sample', 'least_similar_distance'])\n",
    "    \n",
    "    def print_clusters(clusters, label):\n",
    "        num_rows = X.shape[0]\n",
    "        for ac in clusters:\n",
    "            indices = X.index[pred == ac]\n",
    "            rows_for_cluster = X_tfidf[pred == ac]\n",
    "            centroid = kmeans.cluster_centers_[ac]\n",
    "            least_distance = 0\n",
    "            most_similar = None\n",
    "            greatest_distance = 1\n",
    "            least_similar = None\n",
    "            for i in range(rows_for_cluster.shape[0]):\n",
    "                row = np.asarray(rows_for_cluster[i].todense()).reshape(-1)\n",
    "                distance = cosine(centroid, row)\n",
    "                if most_similar is None or least_distance > distance:\n",
    "                    least_distance = distance\n",
    "                    most_similar = i\n",
    "        \n",
    "                if least_similar is None or greatest_distance < distance:\n",
    "                    greatest_distance = distance\n",
    "                    least_similar = i\n",
    "                \n",
    "            pct = round(np.count_nonzero(pred == ac) / num_rows, 2)\n",
    "            writer.writerow([1 if label == 'anomaly' else 0,\n",
    "                             pos_df[pos_df[\"cluster2\"] == ac]['tfidf_text'].sum(),\n",
    "                             neg_df[neg_df[\"cluster2\"] == ac]['tfidf_text'].sum(),\n",
    "                             ac, pct,\n",
    "                             input_data.loc[indices[most_similar], 'text'], round(least_distance, 3),                  \n",
    "                             input_data.loc[indices[least_similar], 'text'], round(greatest_distance, 3)])\n",
    "    print_clusters(anomaly_clusters, 'anomaly')\n",
    "    print_clusters(normal_clusters,  ' normal')\n",
    "    \n",
    "summary_df = pd.read_csv(summary_file_name)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa414d",
   "metadata": {},
   "source": [
    "# Mispredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa9483",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ac in anomaly_clusters:\n",
    "    indices = input_data.index[(pred == ac) & (input_data['label'] == 0)]\n",
    "    if indices.size == 0:\n",
    "        continue\n",
    "    print('False Positives for cluster', ac, 'count', indices.size)\n",
    "    print(np.unique(input_data.loc[indices, 'text'].values))\n",
    "    print(np.unique(input_data.loc[indices, 'tfidf_text'].values))\n",
    "\n",
    "for nc in normal_clusters:\n",
    "    indices = input_data.index[(pred == nc) & (input_data['label'] == 1)]\n",
    "    if indices.size == 0:\n",
    "        continue\n",
    "    print('False Negatives for cluster', nc, 'count', indices.size)\n",
    "    print(np.unique(input_data.loc[indices, 'text'].values))\n",
    "    print(np.unique(input_data.loc[indices, 'tfidf_text'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de13066",
   "metadata": {},
   "source": [
    "# Use TFIDF and KMeans from above to predict anomalies in original raw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aac3d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_to_label_map = np.zeros(k)\n",
    "for c in anomaly_clusters:\n",
    "    cluster_to_label_map[c] = 1\n",
    "    \n",
    "for c in normal_clusters:\n",
    "    cluster_to_label_map[c] = 0\n",
    "\n",
    "mispredictions_file_name = BASE_DIR + APP_SYS_NAME + '_mispredictions.csv'\n",
    "output_file = open(summary_file_name, 'w')\n",
    "\n",
    "def process_raw_file(raw_filename, parser):\n",
    "    block_size = 100000 # entire dataset will not fit in memory, so do a block at a time\n",
    "    file_path = raw_filename.split('/')\n",
    "    with open(raw_filename, \"r\", encoding=\"utf8\", errors='ignore') as raw_file:\n",
    "        count = 0\n",
    "        fp_total = tp_total = fn_total = 0\n",
    "        row_block = []\n",
    "        y_block = np.zeros(block_size)\n",
    "        for line in raw_file:\n",
    "            line = line.rstrip('\\n')\n",
    "            epochts,text,is_anomaly,filename = parser(file_path, line)\n",
    "            y_block[count % block_size] = 1 if is_anomaly else 0\n",
    "            count += 1\n",
    "            row_block.append(text)\n",
    "            \n",
    "            if count % block_size == 0:\n",
    "                X_block = tfidf.transform(row_block)\n",
    "                block_clusters = kmeans.predict(X_block)\n",
    "                block_pred = np.zeros(block_size)\n",
    "                for i in range(block_clusters.shape[0]):\n",
    "                    block_pred[i] = cluster_to_label_map[block_clusters[i]]\n",
    "                        \n",
    "                fp = (block_pred == 1) & (y_block == 0)\n",
    "                tp = (block_pred == 1) & (y_block == 1)\n",
    "                fn = (block_pred == 0) & (y_block == 1)\n",
    "                fp_total += np.count_nonzero(fp)\n",
    "                tp_total += np.count_nonzero(tp)\n",
    "                fn_total += np.count_nonzero(fn)\n",
    "                print(count, fp_total, tp_total, fn_total)\n",
    "                row_block = []\n",
    "\n",
    "            # Remove this condition to process full file.\n",
    "            if count > 3000000: break\n",
    "        print(raw_filename, 'precision', tp_total / (fp_total + tp_total))\n",
    "        print(raw_filename, 'recall', tp_total / (fn_total + tp_total))\n",
    "\n",
    "process_raw_file(RAW_DIR + APP_SYS_NAME + '/' + APP_SYS_NAME + '.log', parsers[APP_SYS_NAME])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1af188",
   "metadata": {},
   "source": [
    "# Compute precision, recall, homogeneity, confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfc792a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def report(report_name, pred, labels):\n",
    "    label_pred = np.zeros(pred.size)\n",
    "    for i in range(pred.size):\n",
    "        label_pred[i] = cluster_to_label_map[pred[i]]\n",
    "    kmeans_report = pd.DataFrame(classification_report(labels, label_pred, output_dict=True))\n",
    "    print(f\"{report_name} Result:\\n================================================\")        \n",
    "    print(f\"Accuracy Score: {accuracy_score(labels, label_pred) * 100:.2f}%\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"CLASSIFICATION REPORT:\\n{kmeans_report}\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"Confusion Matrix: \\n {confusion_matrix(labels, label_pred)}\\n\")\n",
    "    \n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"Completeness Score: \\n {completeness_score(labels, pred)}\\n\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"Homogeneity Score: \\n {homogeneity_score(labels, pred)}\\n\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f'F1 Score: \\n {f1_score(labels, label_pred)}')\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f'Precision Score: \\n {precision_score(labels, label_pred)}')\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f'Recall Score: \\n {recall_score(labels, label_pred)}')\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f'Roc AUC Score: \\n {roc_auc_score(labels, label_pred)}')\n",
    "   \n",
    "    ConfusionMatrixDisplay.from_predictions(labels, label_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    PrecisionRecallDisplay.from_predictions(labels, label_pred, name=report_name)\n",
    "    plt.show()\n",
    "\n",
    "report(APP_SYS_NAME, pred, output.label.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4026431",
   "metadata": {},
   "source": [
    "# TSNE Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bd6e17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "tfidf_tsne = TfidfVectorizer()\n",
    "X_tfidf_tsne = tfidf_tsne.fit_transform(input_data.loc[X.index, 'text'])\n",
    "\n",
    "print(output.shape[0])\n",
    "output_sample = output.sample(1500, random_state=0)\n",
    "X_tfidf_sample = X_tfidf_tsne[output_sample.index]\n",
    "\n",
    "for perplexity in range(35, 36, 5):\n",
    "    tsne = TSNE(n_components=2, verbose=0, perplexity=perplexity, n_iter=1000, learning_rate='auto', random_state=1, init=\"random\")\n",
    "    tsne_result = tsne.fit_transform(np.asarray(X_tfidf_sample.todense()))\n",
    "    plt.figure(figsize=(8,5))\n",
    "\n",
    "\n",
    "    tsne_df = output_sample.copy()\n",
    "    tsne_df['tsne_one'] = tsne_result[:,0]\n",
    "    tsne_df['tsne_two'] = tsne_result[:,1]\n",
    "\n",
    "    ax= sns.scatterplot(\n",
    "        x='tsne_one', y='tsne_two',\n",
    "        hue=\"cluster2\",\n",
    "        palette=sns.color_palette(\"hls\", 20),\n",
    "        #palette=sns.color_palette(\"blend:white,white\"),\n",
    "        data=tsne_df,\n",
    "        legend=None,\n",
    "        alpha=1,\n",
    "    )\n",
    "    ax.set(xlabel=None, ylabel=None)\n",
    "    ax.tick_params(labelleft=False, left=False, labelbottom=False, bottom=False)\n",
    "    ax.set_frame_on(False)\n",
    "\n",
    "    label_df = tsne_df[tsne_df['label'] == 1]\n",
    "    \n",
    "    legend_elements = [Line2D([0], [0], marker=u'$\\u25CC$', color='white', markeredgecolor='black', label='True Positive', markerfacecolor='white', markersize=10, alpha=1),\n",
    "                       Line2D([0], [0], marker='o', color='white', markeredgecolor='red', label='False Positive', markerfacecolor='white', markersize=10),\n",
    "                       Line2D([0], [0], marker='o', color='white', markeredgecolor='green', label='False Negative', markerfacecolor='white', markersize=10)]\n",
    "    ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "    tsne_centers = np.zeros((kmeans.cluster_centers_.shape[0], 2))\n",
    "    tsne_radius = np.zeros(kmeans.cluster_centers_.shape[0])\n",
    "    for i in range(kmeans.cluster_centers_.shape[0]):\n",
    "        tsne_cluster = tsne_result[output_sample.cluster2 == i]\n",
    "        if tsne_cluster.sum() == 0: continue\n",
    "        tsne_centers[i] = np.mean(tsne_cluster, axis=0)\n",
    "        tsne_radius[i] = np.max(np.max(tsne_cluster, axis=0) - np.min(tsne_cluster, axis=0))\n",
    "    \n",
    "    anomaly_tsne_centers = tsne_centers[anomaly_clusters]\n",
    "    anomaly_tsne_radius = tsne_radius[anomaly_clusters]\n",
    "    plt.scatter(anomaly_tsne_centers[:, 0], anomaly_tsne_centers[:, 1], s=anomaly_tsne_radius*200,\n",
    "                facecolors='none', edgecolors='black', linestyle='dashed')\n",
    "    \n",
    "    false_negatives = tsne_result[output_sample.cluster2.isin(normal_clusters) & (output_sample.label == 1)]\n",
    "    plt.scatter(false_negatives[:, 0], false_negatives[:, 1], s=100, facecolors='none', edgecolors='green')\n",
    "    \n",
    "    false_positives = tsne_result[output_sample.cluster2.isin(anomaly_clusters) & (output_sample.label == 0)]\n",
    "    plt.scatter(false_positives[:, 0], false_positives[:, 1], s=100, facecolors='none', edgecolors='red')\n",
    "    \n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f861e34",
   "metadata": {},
   "source": [
    "# Predictability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c82577",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_df = pd.DataFrame()\n",
    "cluster_seq = input_data[['cluster2']].values\n",
    "#cluster_seq = np.arange(50)\n",
    "y_df = np.squeeze(cluster_seq)\n",
    "\n",
    "print('uniq clusters', np.unique(y_df))\n",
    "\n",
    "for w in range(1, 6):\n",
    "    if w == 0:\n",
    "        continue\n",
    "    col = \"w+\" + str(w)\n",
    "    padding = np.ones((1, w)) * -1\n",
    "    window_df[col] = np.append(cluster_seq[w:], padding)\n",
    "\n",
    "n = len(cluster_seq)\n",
    "for w in range(1, 6):\n",
    "    if w == 0:\n",
    "        continue\n",
    "    col = \"w-\" + str(w)\n",
    "    padding = np.ones((1, w)) * -1\n",
    "    window_df[col] = np.append(padding, cluster_seq[:n-w])\n",
    "\n",
    "    \n",
    "print(window_df.head(10))\n",
    "print('window', window_df.shape, 'y_df', y_df.shape)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(window_df, y_df)\n",
    "print('classes', gnb.classes_)\n",
    "\n",
    "idx = np.ones(gnb.classes_.max() + 1).astype(int) * -1\n",
    "for i, c in enumerate(gnb.classes_):\n",
    "    idx[c] = i\n",
    "\n",
    "print('idx', idx)\n",
    "\n",
    "probs = gnb.predict_proba(window_df)\n",
    "pred_probs = np.zeros(probs.shape[0])\n",
    "for i in range(probs.shape[0]):\n",
    "    col = idx[y_df[i]]\n",
    "    pred_probs[i] = probs[i, col]\n",
    "\n",
    "\n",
    "prob_totals = np.zeros(probs.shape[1])\n",
    "prob_counts = np.zeros(probs.shape[1])\n",
    "for i in range(probs.shape[1]):\n",
    "    cls = gnb.classes_[i]\n",
    "    prob_totals[i] = pred_probs[y_df == cls].sum()\n",
    "    prob_counts[i] = np.count_nonzero(y_df == cls)\n",
    "    #print('probs', i, cls, prob_totals[i], prob_counts[i])\n",
    "\n",
    "predictiveness = prob_totals / prob_counts\n",
    "print(predictiveness)\n",
    "print(np.argsort(predictiveness))\n",
    "\n",
    "\n",
    "for i in anomaly_clusters:\n",
    "    print('anomaly cluster', i, 'predictiveness', predictiveness[idx[i]])\n",
    "\n",
    "for i in normal_clusters:\n",
    "    print('normal cluster', i, 'predictiveness', predictiveness[idx[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a57bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "num_clusters = input_data['cluster2'].max() + 1\n",
    "stats_df = pd.DataFrame({'cluster': [j for j in range(num_clusters)]})\n",
    "\n",
    "kurt_results = []\n",
    "skew_results = []\n",
    "\n",
    "offset = 0\n",
    "block_size = 10000\n",
    "while offset < len(input_data):\n",
    "    block_df = input_data.iloc[offset:offset+block_size]\n",
    "    mean_timestamp = block_df['timestamp'].mean()\n",
    "    offset += block_size\n",
    "    for k in range(num_clusters):\n",
    "        block = block_df[block_df['cluster2'] == k]['timestamp'].values - mean_timestamp\n",
    "        if len(block) == 0:\n",
    "            b_kurt = b_skew = 0\n",
    "        else:\n",
    "            b_kurt = kurtosis(block)\n",
    "            b_skew = skew(block)\n",
    "        kurt_results.append((b_kurt, k))\n",
    "        skew_results.append((b_skew, k))\n",
    "\n",
    "kurt_results = sorted(kurt_results, reverse=True)\n",
    "skew_results = sorted(skew_results, reverse=True)\n",
    "\n",
    "\n",
    "min_timestamp = input_data['timestamp'].min()\n",
    "\n",
    "def cluster_dist(k):\n",
    "    result = input_data[input_data['cluster2'] == k]['timestamp'] - min_timestamp\n",
    "    if result.size == 0:\n",
    "        result = input_data['timestamp'] - min_timestamp\n",
    "    np_result = np.asarray(result.values)\n",
    "    mean = np_result.mean()\n",
    "    std = np_result.std()\n",
    "    np_result = (np_result - mean) / std\n",
    "    stats_df.at[k, 'kurtosis'] = kurtosis(np_result)\n",
    "    stats_df.at[k, 'skew'] = skew(np_result)\n",
    "\n",
    "for k in range(num_clusters):\n",
    "    cluster_dist(k)\n",
    "\n",
    "stats_df.dropna()\n",
    "print(input_data[['cluster2', 'label', 'clusters']].groupby(['cluster2', 'label']).count())\n",
    "for col in stats_df.columns:\n",
    "    print(col, np.argsort(stats_df[col].values))\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "\n",
    "random_state=5\n",
    "\n",
    "for ModelClass in [IsolationForest, SGDOneClassSVM]:\n",
    "    model = ModelClass(random_state=random_state)\n",
    "    model_pred = model.fit_predict(X_tfidf)\n",
    "    model_pred[model_pred == 1] = 0\n",
    "    model_pred[model_pred == -1] = 1\n",
    "    model_name = type(model).__name__\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Label counts\", np.bincount(model_pred))\n",
    "    print(f\"Completeness Score: \\n {completeness_score(model_pred, pred)}\\n\")\n",
    "    print(f\"Homogeneity Score: \\n {homogeneity_score(model_pred, pred)}\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
