{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = ''\n",
    "APP_SYS_NAME = 'BGL'\n",
    "#APP_SYS_NAME = 'Thunderbird'\n",
    "\n",
    "BASE_DIR = PROJECT_DIR + 'output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, confusion_matrix , precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from scipy.spatial.distance import cosine\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import random\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(2)\n",
    "sys.path.append(PROJECT_DIR) # this is done to make the import of ad_feature_extraction work\n",
    "from ad_feature_extraction import parsers\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "random_state=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4f1c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(BASE_DIR + APP_SYS_NAME + '_clusters2.csv')\n",
    "\n",
    "print(\"Input_data Shape:\",input_data.shape)\n",
    "print(input_data['label'].value_counts())\n",
    "\n",
    "sns.countplot(x=input_data['label'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f153498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGradientBoostingClassifier():\n",
    "    return GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "def createLogisticRegression():\n",
    "    return LogisticRegression(class_weight='balanced', random_state=random_state)\n",
    "\n",
    "def createXGBClassifier():\n",
    "    return XGBClassifier(booster=\"gbtree\", n_estimators=2, max_depth=2, learning_rate=0.3, objective='binary:logistic')\n",
    "\n",
    "def createIsolationForest(contamination=0.05):\n",
    "    return IsolationForest(contamination=contamination, random_state=random_state)\n",
    "\n",
    "def createSGDOneClassSVM(nu = 0.05):\n",
    "    return SGDOneClassSVM(nu=nu, shuffle=True, fit_intercept=True, random_state=42, tol=1e-4)\n",
    "\n",
    "def getSupervisedModels():\n",
    "    return [createGradientBoostingClassifier(), createLogisticRegression(), createXGBClassifier()]\n",
    "\n",
    "def getUnsupervisedModels(threshold=0.05):\n",
    "    return [createIsolationForest(threshold), createSGDOneClassSVM(threshold)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5e473",
   "metadata": {},
   "source": [
    "# Effect of cluster filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba4eb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusters = input_data['clusters'].values\n",
    "clusters2 = input_data['cluster2'].values\n",
    "\n",
    "print(\"Between first and second clustering:____________________________\")\n",
    "print(f\"Completeness Score: \\n {completeness_score(clusters, clusters2)}\\n\")\n",
    "print(f\"Homogeneity Score: \\n {homogeneity_score(clusters, clusters2)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce927f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = input_data['label']\n",
    "print(\"Between first clusters and label:____________________________\")\n",
    "print(f\"Completeness Score: \\n {completeness_score(labels, clusters)}\\n\")\n",
    "print(f\"Homogeneity Score: \\n {homogeneity_score(labels, clusters)}\\n\") \n",
    "\n",
    "print(\"Between second clusters and label:____________________________\")\n",
    "print(f\"Completeness Score: \\n {completeness_score(labels, clusters2)}\\n\")\n",
    "print(f\"Homogeneity Score: \\n {homogeneity_score(labels, clusters2)}\\n\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26edf969",
   "metadata": {},
   "source": [
    "# Parameter effect on supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(report_name, label_pred, labels):\n",
    "    report = pd.DataFrame(classification_report(labels, label_pred, output_dict=True))\n",
    "    print(f\"{report_name} Result:\\n================================================\")        \n",
    "    print(f\"Accuracy Score: {accuracy_score(labels, label_pred) * 100:.2f}%\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"CLASSIFICATION REPORT:\\n{report}\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"Confusion Matrix: \\n {confusion_matrix(labels, label_pred)}\\n\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f'F1 Score: \\n {f1_score(labels, label_pred)}')\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f'Precision Score: \\n {precision_score(labels, label_pred)}')\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f'Recall Score: \\n {recall_score(labels, label_pred)}')\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f'Roc AUC Score: \\n {roc_auc_score(labels, label_pred)}')\n",
    "   \n",
    "    ConfusionMatrixDisplay.from_predictions(labels, label_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    PrecisionRecallDisplay.from_predictions(labels, label_pred, name=report_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8bfae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(BASE_DIR + APP_SYS_NAME + '_train_params.csv')\n",
    "test = pd.read_csv(BASE_DIR + APP_SYS_NAME + '_test_params.csv')\n",
    "\n",
    "#print(\"Train Shape:\",train.shape,\"Test Shape:\",test.shape)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "X_clusters = input_data.copy()\n",
    "X_dummies = pd.get_dummies(X_clusters['clusters'])\n",
    "X_clusters['label'] = le.fit_transform(X_clusters['label'])\n",
    "\n",
    "train_dummies = pd.get_dummies(train['clusters'])\n",
    "train['label'] = le.fit_transform(train['label'])\n",
    "\n",
    "test_dummies = pd.get_dummies(test['clusters'])\n",
    "test['label'] = le.fit_transform(test['label'])\n",
    "\n",
    "for col in train_dummies.columns:\n",
    "    if not col in test_dummies.columns:\n",
    "        continue\n",
    "    col_name = 'c_' + str(col)\n",
    "    train[col_name] = train_dummies[col]\n",
    "    test[col_name] = test_dummies[col]\n",
    "\n",
    "for col in X_dummies.columns:\n",
    "    col_name = 'c_' + str(col)\n",
    "    X_clusters[col_name] = X_dummies[col]\n",
    "\n",
    "for col in train.columns:\n",
    "    if col not in test.columns:\n",
    "        test[col] = 0\n",
    "\n",
    "for col in test.columns:\n",
    "    if col not in train.columns:\n",
    "        train[col] = 0\n",
    "\n",
    "cols_without_params = [col for col in train.columns if col.startswith('c_')]\n",
    "cols_with_params = cols_without_params + [col for col in train.columns if col.startswith('p_')]\n",
    "\n",
    "def evaluate_training_set(report_name, cols):\n",
    "    # Supervised\n",
    "    X_train = train[cols]\n",
    "    y_train = train.loc[:,'label']\n",
    "    X_test = test[cols]\n",
    "    y_test = test.loc[:,'label']\n",
    "    for clf in getSupervisedModels():\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_pred = clf.predict(X_train)\n",
    "        test_pred = clf.predict(X_test)\n",
    "        model_name = type(clf).__name__\n",
    "        report(report_name + ' ' + model_name + ' Train', train_pred, y_train)\n",
    "        report(report_name + ' ' + model_name + ' Test', test_pred, y_test)\n",
    "\n",
    "def evaluate_unsupervised(report_name, cols):\n",
    "    # Unsupervised\n",
    "    X = X_clusters[cols]\n",
    "    y = X_clusters.loc[:,'label']\n",
    "    for clf in getUnsupervisedModels():\n",
    "        model_pred = clf.fit_predict(X)\n",
    "        model_pred[model_pred == 1] = 0\n",
    "        model_pred[model_pred == -1] = 1\n",
    "        model_name = type(clf).__name__\n",
    "        report(report_name + ' ' + model_name, model_pred, y)\n",
    "    \n",
    "evaluate_training_set('With Params', cols_without_params)\n",
    "evaluate_training_set('Without Params', cols_with_params)\n",
    "\n",
    "cols_without_params = [col for col in X_clusters.columns if col.startswith('c_')]\n",
    "cols_with_params = cols_without_params + [col for col in X_clusters.columns if col.startswith('p_')]\n",
    "\n",
    "evaluate_unsupervised('With Params', cols_without_params)\n",
    "evaluate_unsupervised('Without Params', cols_with_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196fbde",
   "metadata": {},
   "source": [
    "# Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b87ee50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sliding_window_df = pd.read_csv(BASE_DIR + APP_SYS_NAME + '_sliding_window.csv')\n",
    "cluster_cols = [col for col in sliding_window_df.columns if col.startswith('cluster_')]\n",
    "\n",
    "#label_field = 'precision_label'\n",
    "label_field = 'recall_label'\n",
    "\n",
    "def simple_split(df):\n",
    "    split_on = int(len(df.values)*0.50)\n",
    "    train = df.values[:split_on]\n",
    "    test = df.values[split_on:]\n",
    "    train_df = pd.DataFrame(data=train, columns=df.columns)\n",
    "    test_df = pd.DataFrame(data=test, columns=df.columns)\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = simple_split(sliding_window_df)\n",
    "train_df[label_field] = train_df[label_field].astype('int')\n",
    "test_df[label_field] = test_df[label_field].astype('int')\n",
    "\n",
    "X_win_train = train_df[cluster_cols].astype('int')\n",
    "y_win_train = train_df.loc[:, label_field]\n",
    "X_win_test = test_df[cluster_cols].astype('int')\n",
    "y_win_test = test_df.loc[:, label_field]\n",
    "\n",
    "for clf in getSupervisedModels():\n",
    "    clf.fit(X_win_train, y_win_train)\n",
    "    train_pred = clf.predict(X_win_train)\n",
    "    test_pred = clf.predict(X_win_test)\n",
    "    model_name = type(clf).__name__\n",
    "    #report('Sliding Window ' + model_name + ' Train', train_pred, y_win_train)\n",
    "    report('Sliding Window ' + model_name + ' Test', test_pred, y_win_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da43c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "X_window = sliding_window_df[cluster_cols].astype('int')\n",
    "y_precision = sliding_window_df['precision_label']\n",
    "y_recall = sliding_window_df['recall_label']\n",
    "\n",
    "for clf in getUnsupervisedModels():\n",
    "    model_pred = clf.fit_predict(X_window)\n",
    "    model_pred[model_pred == 1] = 0\n",
    "    model_pred[model_pred == -1] = 1\n",
    "    model_name = type(clf).__name__\n",
    "    #report(model_name + ' Precision', model_pred, y_precision)\n",
    "    report('Sliding Window ' + model_name + ' Recall', model_pred, y_recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708bef0",
   "metadata": {},
   "source": [
    "# TFIDF Before and After Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cbf75b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "for txt_col in ['text', 'tfidf_text']:\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf.fit_transform(train[txt_col])\n",
    "    print('Shape for', txt_col, X_train_tfidf.shape)\n",
    "    y_train = train.loc[:,'label']\n",
    "    X_test_tfidf = tfidf.transform(test[txt_col])\n",
    "    y_test = test.loc[:,'label']\n",
    "\n",
    "    for clf in getSupervisedModels():\n",
    "        clf.fit(X_train_tfidf, y_train)\n",
    "        train_pred = clf.predict(X_train_tfidf)\n",
    "        test_pred = clf.predict(X_test_tfidf)\n",
    "        model_name = type(clf).__name__\n",
    "        report('TFIDF ' + txt_col + ' ' + model_name + ' Test', test_pred, y_test)\n",
    "\n",
    "    \n",
    "    X_tfidf = tfidf.fit_transform(input_data[txt_col])\n",
    "    y = input_data.loc[:,'label']\n",
    "    for clf in getUnsupervisedModels():\n",
    "        model_pred = clf.fit_predict(X_tfidf)\n",
    "        model_pred[model_pred == 1] = 0\n",
    "        model_pred[model_pred == -1] = 1\n",
    "        model_name = type(clf).__name__\n",
    "        report('TFIDF ' + txt_col + ' ' + model_name + ' Recall', model_pred, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a11ced9",
   "metadata": {},
   "source": [
    "# Unsupervised Thresholds vs F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc4b95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform(input_data['tfidf_text'])\n",
    "y = input_data.loc[:,'label']\n",
    "thresholds = np.linspace(0.05, 0.5, num=10)\n",
    "score_map = {'IsolationForest': {'f1s': [], 'precisions': [], 'recalls': []},\n",
    "             'SGDOneClassSVM': {'f1s': [], 'precisions': [], 'recalls': []},\n",
    "            }\n",
    "for threshold in thresholds:\n",
    "    for clf in getUnsupervisedModels(threshold):\n",
    "        model_pred = clf.fit_predict(X_tfidf)\n",
    "        model_pred[model_pred == 1] = 0\n",
    "        model_pred[model_pred == -1] = 1\n",
    "        model_name = type(clf).__name__\n",
    "        f1 = f1_score(labels, model_pred)\n",
    "        precision = precision_score(labels, model_pred)\n",
    "        recall = recall_score(labels, model_pred)\n",
    "        score_map[model_name]['f1s'].append(f1)\n",
    "        score_map[model_name]['precisions'].append(precision)\n",
    "        score_map[model_name]['recalls'].append(recall)\n",
    "        print(f'{model_name}  F1 Score @ {round(threshold, 2)}: {round(f1, 4)}')\n",
    "        print(f'{model_name} Precision @ {round(threshold, 2)}: {round(precision, 4)}')\n",
    "        print(f'{model_name}    Recall @ {round(threshold, 2)}: {round(recall, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a920f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name, results in score_map.items():\n",
    "    f1s = results['f1s']\n",
    "    precisions = results['precisions']\n",
    "    recalls = results['recalls']\n",
    "    plt.figure(figsize=(5, 3),dpi=250)\n",
    "    plt.plot(thresholds, f1s, label='F1')\n",
    "    plt.plot(thresholds, precisions, label='precision')\n",
    "    plt.plot(thresholds, recalls, label='recall')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('Performance by threshold for ' + model_name + ' on ' + APP_SYS_NAME)\n",
    "    plt.ylabel('score')\n",
    "    plt.xlabel('nu' if model_name == 'SGDOneClassSVM' else 'contamination')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339efb19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
